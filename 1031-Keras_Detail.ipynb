{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN4HFi5CvT12Ra+6bR3OvK1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"VwBW76EhPkRt"},"outputs":[],"source":["# Weight의 초기화 방식에 대해서 알아보아요!!\n","from tensorflow.keras.layers import Dense\n","\n","dense = Dense(units=5,\n","              activation='relu',\n","              kernel_initializer='he_normal')\n","\n","dense.get_config()"]},{"cell_type":"code","source":["# Regularization(규제)는 어떻게 적용해야 할까요?\n","# Tensorflow Keras는 규제를 기본적으로 적용하지 않아요!\n","# 당연히 Dense Layer설정에서 규제를 지정해 주면 되요!\n","\n","from tensorflow.keras.regularizers import l1, l2\n","\n","dense = Dense(units=5,\n","              activation='relu',\n","              kernel_regularizer=l2(l2=0.1))\n","\n","dense.get_config()"],"metadata":{"id":"c_gV5t0WWMlt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dropout을 이용하면 Model의 overfitting을 줄일 수 있어요!\n","# Tensorflow Keras에서는 이 Dropout을 layer로 제공해요!\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dropout, Flatten, Dense\n","\n","model = Sequential()\n","\n","model.add(Flatten(input_shape=(784,)))\n","\n","model.add(Dense(units=128,\n","                activation='relu'))\n","model.add(Dropout(rate=0.25))\n","model.add(Dense(units=64,\n","                activation='relu'))\n","\n","\n"],"metadata":{"id":"fH-joNCEaSS8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 이번에는 학습을 좀 더 잘 되게 하기 위해 사용되는 batch normalization을 사용해 보아요!\n","# keras에서는 layer로 제공됩니다.\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dropout, Flatten\n","from tensorflow.keras.layers import Dense, BatchNormalization, Activation\n","\n","model = Sequential([\n","    Flatten(input_shape=(784,)),\n","    Dense(units=32),\n","    BatchNormalization(),\n","    Activation('relu'),\n","    Dropout(rate=0.25),\n","    Dense(units=64,\n","                activation='relu')\n","])\n"],"metadata":{"id":"a5dmg7x1cVxd","executionInfo":{"status":"ok","timestamp":1698734408619,"user_tz":-540,"elapsed":3,"user":{"displayName":"문성훈","userId":"17340983977521415755"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Callback기능중에 ModelCheckpoint에 대해서 알아보아요!\n","# ModelCheckpoint에 모델 저장기능이예요!\n","\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","modelcp = ModelCheckpoint(filepath='tmp_checkpoint.ckpt',\n","                          save_weights_only=True,\n","                          save_best_only=True,\n","                          monitor='val_loss',\n","                          verbose=1)\n","\n","model.fit(x_data_train,\n","          t_data_train,\n","          epochs=200,\n","          verbose=1,\n","          batch_size=100,\n","          validation_split=0.3,\n","          callbacks=[modelcp])\n","\n","# 나중에 파일로 저장되어 있는 이 ModelCheckpoint 파일을 로드하려면\n","\n","model.load_weights('tmp_checkpoint.ckpt')"],"metadata":{"id":"-j1RvHcSkGrf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습의 조기종료\n","# EarlyStopping\n","\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# 1 epoch : val_loss => 0.1\n","# 2 epoch : val_loss => 0.05\n","# 3 epoch : val_loss => 0.04\n","# 4 epoch : val_loss => 0.05\n","# 5 epoch : val_loss => 0.044\n","# 6 epoch : val_loss => 0.03\n","es = EarlyStopping(monitor='val_loss',\n","                   patience=5,\n","                   restore_best_weights=True\n","                   )\n","# restore_best_weights : 학습이 끝난 후 가장 좋은 weights값으로\n","# 모델의 weight값을 설정.\n","\n","model.fit(x_data_train,\n","          t_data_train,\n","          epochs=200,\n","          verbose=1,\n","          batch_size=100,\n","          validation_split=0.3,\n","          callbacks=[modelcp, es])\n"],"metadata":{"id":"Oe4nqaRJm9K5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 내용정리를 좀 해야 하구요!\n","# 기존에 Fashion-MNIST 구현한 내용이 있을꺼예요!\n","# 1. Multinomial Classification(logistic regression - Machine Learning)\n","# 2. DNN으로 구현\n","# 3. CNN으로 구현.\n","\n","# CNN으로 구현하는데 어제 구현한 모델과\n","# 오늘 구현할 모델은 keras기능을 적용해서 실습을 진행해 보시면 되요~!\n","# 적용할 내용은 ..\n","# 규제, dropout, 배치정규화, callbacks\n"],"metadata":{"id":"QiW-zj2QdLvG"},"execution_count":null,"outputs":[]}]}